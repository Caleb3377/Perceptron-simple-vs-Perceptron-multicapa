{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proyecto Redes Neuronales. Compración Perceptrón simple vs Perceptrón multicapa en  clasificación"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Según los CDC, las enfermedades del corazón son una de las principales causas de muerte. Aproximadamente la mitad de los estadounidenses (47%) presentan al menos uno de los tres factores de riesgo clave de las enfermedades cardíacas: presión arterial alta, colesterol alto y tabaquismo. Otros indicadores clave son la condición de diabético, la obesidad (IMC elevado), la falta de actividad física o el consumo excesivo de alcohol. Detectar y prevenir los factores que más influyen en las enfermedades del corazón es muy importante en la asistencia sanitaria. Los avances informáticos, por su parte, permiten aplicar métodos de aprendizaje automático para detectar \"patrones\" a partir de los datos que puedan predecir el estado de un paciente.\n",
    "\n",
    "En este proyecto vas a **comparar la eficacia de dos métodos diferentes en la predicción del riesgo de padecer una enfermedad cardiaca**. \n",
    "\n",
    "El conjunto de datos procede de los CDC y es una parte importante del Sistema de Vigilancia de los Factores de Riesgo en el Comportamiento, que realiza encuestas telefónicas anuales para recopilar datos sobre el estado de salud de los residentes en EE.UU. El dataset original tiene casi 300 variables, pero se ha reducido a sólo unas 20 variables. \n",
    "\n",
    "Tienes que realizar las siguientes tareas:\n",
    "    - Crear una función perceptron simple que dado un ejemplo o conjunto de ejemplos devuelva la clase predicha (-1, 1).\n",
    "    - Crear una función para calcular el coste 'bisagra' para medir el error en clasificación.\n",
    "    - Crear una función que calcule el gradiente de la función de coste por cada variable del perceptrón.\n",
    "    - Programar el algortimo del descenso con gradiente y obtener los parámetros del perceptrón que mejor se ajusten a los datos de entrenamiento.\n",
    "    - Calcular la matriz de confusión en los ejemplos de test.\n",
    "    - Utilizando la librería sklearn entrenar 2 arquitecturas diferentes de redes neuronales.\n",
    "    - Comparar las matrices de confusión de las Redes Neuronales con al obtenida por el perceptrón."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente celda se leen los datos y se generan los conjuntos de entrenamiento y de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HeartDisease</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>AlcoholDrinking</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>DiffWalking</th>\n",
       "      <th>Sex</th>\n",
       "      <th>AgeCategory</th>\n",
       "      <th>Race</th>\n",
       "      <th>Diabetic</th>\n",
       "      <th>PhysicalActivity</th>\n",
       "      <th>GenHealth</th>\n",
       "      <th>Asthma</th>\n",
       "      <th>KidneyDisease</th>\n",
       "      <th>SkinCancer</th>\n",
       "      <th>BMI</th>\n",
       "      <th>PhysicalHealth</th>\n",
       "      <th>MentalHealth</th>\n",
       "      <th>SleepTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33522</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>25.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22090</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8570</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31865</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57751</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.15</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       HeartDisease  Smoking  AlcoholDrinking  Stroke  DiffWalking  Sex  \\\n",
       "33522             1        1                0       0            0    1   \n",
       "22090             0        1                0       0            0    1   \n",
       "8570              0        0                0       0            0    0   \n",
       "31865             0        1                1       0            0    1   \n",
       "57751             1        1                0       0            0    1   \n",
       "\n",
       "       AgeCategory  Race  Diabetic  PhysicalActivity  GenHealth  Asthma  \\\n",
       "33522           11     5         0                 1          2       0   \n",
       "22090            5     3         0                 1          2       0   \n",
       "8570             7     5         0                 1          0       0   \n",
       "31865            9     5         0                 1          2       0   \n",
       "57751           10     5         2                 0          1       0   \n",
       "\n",
       "       KidneyDisease  SkinCancer    BMI  PhysicalHealth  MentalHealth  \\\n",
       "33522              1           0  25.11             0.0           0.0   \n",
       "22090              0           0  23.56             0.0           0.0   \n",
       "8570               0           0  23.30             0.0           0.0   \n",
       "31865              0           0  37.59             0.0           0.0   \n",
       "57751              0           0  35.15             2.0           2.0   \n",
       "\n",
       "       SleepTime  \n",
       "33522        7.0  \n",
       "22090        7.0  \n",
       "8570         8.0  \n",
       "31865        8.0  \n",
       "57751        6.0  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from typing import Tuple, Optional, List\n",
    "import random\n",
    "\n",
    "datos = pd.read_csv(\"heart_2020.csv\")\n",
    "datos = datos.drop(['Unnamed: 0'], axis=1)\n",
    "datos = shuffle(datos)\n",
    "datos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HeartDisease</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>AlcoholDrinking</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>DiffWalking</th>\n",
       "      <th>Sex</th>\n",
       "      <th>AgeCategory</th>\n",
       "      <th>Race</th>\n",
       "      <th>Diabetic</th>\n",
       "      <th>PhysicalActivity</th>\n",
       "      <th>GenHealth</th>\n",
       "      <th>Asthma</th>\n",
       "      <th>KidneyDisease</th>\n",
       "      <th>SkinCancer</th>\n",
       "      <th>BMI</th>\n",
       "      <th>PhysicalHealth</th>\n",
       "      <th>MentalHealth</th>\n",
       "      <th>SleepTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.00000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.456217</td>\n",
       "      <td>0.49335</td>\n",
       "      <td>0.060150</td>\n",
       "      <td>0.087117</td>\n",
       "      <td>0.229700</td>\n",
       "      <td>0.523233</td>\n",
       "      <td>7.620233</td>\n",
       "      <td>4.611650</td>\n",
       "      <td>0.458683</td>\n",
       "      <td>0.719467</td>\n",
       "      <td>2.231617</td>\n",
       "      <td>0.149533</td>\n",
       "      <td>0.073217</td>\n",
       "      <td>0.127967</td>\n",
       "      <td>28.971355</td>\n",
       "      <td>5.141217</td>\n",
       "      <td>4.201083</td>\n",
       "      <td>7.118750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.498083</td>\n",
       "      <td>0.49996</td>\n",
       "      <td>0.237767</td>\n",
       "      <td>0.282008</td>\n",
       "      <td>0.420643</td>\n",
       "      <td>0.499464</td>\n",
       "      <td>3.413152</td>\n",
       "      <td>1.024753</td>\n",
       "      <td>0.838951</td>\n",
       "      <td>0.449264</td>\n",
       "      <td>1.396139</td>\n",
       "      <td>0.356616</td>\n",
       "      <td>0.260494</td>\n",
       "      <td>0.334055</td>\n",
       "      <td>6.541266</td>\n",
       "      <td>9.761226</td>\n",
       "      <td>8.466793</td>\n",
       "      <td>1.571938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.210000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.410000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.920000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.280000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>93.970000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       HeartDisease      Smoking  AlcoholDrinking        Stroke   DiffWalking  \\\n",
       "count  60000.000000  60000.00000     60000.000000  60000.000000  60000.000000   \n",
       "mean       0.456217      0.49335         0.060150      0.087117      0.229700   \n",
       "std        0.498083      0.49996         0.237767      0.282008      0.420643   \n",
       "min        0.000000      0.00000         0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.00000         0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.00000         0.000000      0.000000      0.000000   \n",
       "75%        1.000000      1.00000         0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.00000         1.000000      1.000000      1.000000   \n",
       "\n",
       "                Sex   AgeCategory          Race      Diabetic  \\\n",
       "count  60000.000000  60000.000000  60000.000000  60000.000000   \n",
       "mean       0.523233      7.620233      4.611650      0.458683   \n",
       "std        0.499464      3.413152      1.024753      0.838951   \n",
       "min        0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      5.000000      5.000000      0.000000   \n",
       "50%        1.000000      8.000000      5.000000      0.000000   \n",
       "75%        1.000000     10.000000      5.000000      0.000000   \n",
       "max        1.000000     12.000000      5.000000      3.000000   \n",
       "\n",
       "       PhysicalActivity     GenHealth        Asthma  KidneyDisease  \\\n",
       "count      60000.000000  60000.000000  60000.000000   60000.000000   \n",
       "mean           0.719467      2.231617      0.149533       0.073217   \n",
       "std            0.449264      1.396139      0.356616       0.260494   \n",
       "min            0.000000      0.000000      0.000000       0.000000   \n",
       "25%            0.000000      1.000000      0.000000       0.000000   \n",
       "50%            1.000000      2.000000      0.000000       0.000000   \n",
       "75%            1.000000      4.000000      0.000000       0.000000   \n",
       "max            1.000000      4.000000      1.000000       1.000000   \n",
       "\n",
       "         SkinCancer           BMI  PhysicalHealth  MentalHealth     SleepTime  \n",
       "count  60000.000000  60000.000000    60000.000000  60000.000000  60000.000000  \n",
       "mean       0.127967     28.971355        5.141217      4.201083      7.118750  \n",
       "std        0.334055      6.541266        9.761226      8.466793      1.571938  \n",
       "min        0.000000     12.210000        0.000000      0.000000      1.000000  \n",
       "25%        0.000000     24.410000        0.000000      0.000000      6.000000  \n",
       "50%        0.000000     27.920000        0.000000      0.000000      7.000000  \n",
       "75%        0.000000     32.280000        4.000000      3.000000      8.000000  \n",
       "max        1.000000     93.970000       30.000000     30.000000     24.000000  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 ... 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from numpy.linalg import inv\n",
    "# Ten en cuenta que la variable y tiene valores (0 y 1)\n",
    "y: np.ndarray = np.array(datos['HeartDisease'])\n",
    "datos = datos.drop(['HeartDisease'], axis=1)\n",
    "X: np.ndarray = StandardScaler().fit_transform(np.array(datos))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size= 0.2, random_state= 2)\n",
    "print(y_test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La librería sklearn tiene implementada una clase MLPClassifier que es un perceptrón multicapa con el algoritmo de backpropagation que podemos utilizar en la siguiente celda se crea un preceptrón con una capa oculta y dos neuronas para que se ajuste a la función XOR.\n",
    "Para ayuda sobre la clase y sus parámetros visitar: https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = np.array([[2,2], [0,0], [2,0], [0,2]])\n",
    "# y = np.array([1, 1, 0, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_p [0 0 1 ... 1 1 1]\n",
      "w [array([[-3.20118910e-04,  7.17136925e-02],\n",
      "       [-6.51574936e-02, -2.75765442e-02],\n",
      "       [-2.61957133e+00,  1.55344346e-01],\n",
      "       [ 2.61865981e-01,  7.49554434e-02],\n",
      "       [ 6.01324541e-02,  1.52584420e-01],\n",
      "       [ 1.79335744e-01,  4.02289183e-01],\n",
      "       [ 1.65123452e-01, -9.48585434e-02],\n",
      "       [-2.39376705e-01,  8.41214392e-02],\n",
      "       [ 9.27840777e-02, -1.33943684e-03],\n",
      "       [-4.68831700e+00, -1.56119341e-01],\n",
      "       [-2.32976212e-02,  5.00813384e-02],\n",
      "       [-8.11601981e-02,  8.10268582e-02],\n",
      "       [-1.82378324e-01,  2.66694741e-02],\n",
      "       [-2.17050936e-01, -1.18041155e-02],\n",
      "       [-1.31715171e+00,  8.71083165e-02],\n",
      "       [-6.35834553e-02,  3.61698688e-02],\n",
      "       [-3.28496371e-02, -2.03828333e-02]]), array([[-2.51011745],\n",
      "       [13.79937941]])]\n",
      "w_0 [array([-8.4509231,  1.1107617]), array([-10.29838286])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yerso\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "# Función para crear el perceptrón multicapa\n",
    "pmc = MLPClassifier(solver='lbfgs', alpha=1e-2, hidden_layer_sizes=(2,), activation='logistic', random_state=1)\n",
    "# Al llamar a fit se realiza el entrenamiento\n",
    "pmc.fit(X_train, y_train)\n",
    "\n",
    "y_p: np.ndarray = pmc.predict(X_test)\n",
    "\n",
    "#Valores predichos\n",
    "print('y_p',y_p)\n",
    "# Valores de los pesos de la red\n",
    "print('w',pmc.coefs_)\n",
    "# Valores de los pesos correspondiente a los bias (x_0)\n",
    "print('w_0',pmc.intercepts_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "conlaFuncion: np.ndarray = confusion_matrix(y_test, y_p, labels=[1,0]).ravel()\n",
    "\n",
    "# [[5027 1510]\n",
    "#  [1344 4119]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| tn | fp | fn | tp |\n",
      "[4186 1225 1548 5041]\n",
      "[5411    0 6589    0]\n",
      "[3953 1458 1424 5165]\n",
      "PESOS ADALINE =  [ 2.55083024  0.25288452  0.02752557  0.23752018  0.00983454 -0.02907052\n",
      "  0.1641354   0.00531853  0.28304671  0.00821699 -0.24740954  0.34079094\n",
      "  0.40204352 -0.01961286 -0.06213849  0.02265898 -0.05431912 -0.02012011]\n",
      "PESOS INI ADALINE=  [ 2.55083024  0.25288452  0.02752557  0.23752018  0.00983454 -0.02907052\n",
      "  0.1641354   0.00531853  0.28304671  0.00821699 -0.24740954  0.34079094\n",
      "  0.40204352 -0.01961286 -0.06213849  0.02265898 -0.05431912 -0.02012011]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class AdalineClassifier:\n",
    "    def __init__(self, alpha: float = 1e-2, random_state: int = 42, iters: int = 100) -> None:\n",
    "        self.alpha: float = alpha\n",
    "        self.random_state: int = random_state\n",
    "        self.iters: int = iters\n",
    "        self.X_train: Optional[np.ndarray] = None\n",
    "        self.y_train: Optional[np.ndarray] = None\n",
    "        self.Loss: Optional[np.ndarray] = None\n",
    "        self.w_ini: Optional[np.ndarray] = None\n",
    "        self.w: Optional[np.ndarray] = None\n",
    "\n",
    "    def getWeigths(self) -> np.ndarray:\n",
    "        return self.w\n",
    "    \n",
    "    def getWeigthsInit(self) -> np.ndarray:\n",
    "        return self.w_ini\n",
    "    \n",
    "    def getLoss(self) -> np.ndarray:\n",
    "        return self.Loss\n",
    "    \n",
    "    def init_weights(self) -> None:\n",
    "        self.w_ini =  np.random.RandomState(self.random_state).uniform(low=-1, high=1, size=(18,))\n",
    "\n",
    "    def perceptron(self, x: np.ndarray) -> int:\n",
    "        return 1 if np.dot(self.w, x)> 0.5 else -1\n",
    "    \n",
    "    def coste(self) -> float:\n",
    "        return np.sum([max(1-(np.dot(self.w, self.X_train[i])*self.y_train[i]), 0) for i in range(np.size(self.y_train))])/np.size(self.y_train)\n",
    "    \n",
    "    def gradientes(self) -> np.ndarray:\n",
    "        diff_W: np.ndarray = np.zeros(self.X_train.shape[1])\n",
    "        for x_i, y_i in zip(self.X_train, self.y_train): \n",
    "            if np.dot(self.w, x_i)*y_i < 1: diff_W -= x_i*y_i\n",
    "        return diff_W/np.size(self.y_train)\n",
    "\n",
    "    def DescensoGradiente(self) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        self.w: np.ndarray = self.w_ini\n",
    "        self.Loss: np.ndarray = np.zeros(self.iters)\n",
    "        for i in range(self.iters):\n",
    "            self.Loss[i] = self.coste()\n",
    "            self.w -= self.alpha * self.gradientes()\n",
    "        return self.Loss, self.w\n",
    "    \n",
    "    def fitAdaline(self, X_train: np.ndarray, y_train: np.ndarray) -> None:\n",
    "        self.init_weights()\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.Loss, self.w = self.DescensoGradiente()\n",
    "\n",
    "    def predictAdaline(self, X_test: np.ndarray) -> np.ndarray:\n",
    "        return  [self.perceptron(X_test[i]) for i in range(len(X_test))]\n",
    "\n",
    "def addBiasColumn(X: np.ndarray) -> np.ndarray:\n",
    "    return np.c_[np.ones(len(X)), X ]\n",
    "\n",
    "def convertNegativeToZeroExpresionMC(y: np.ndarray) -> np.ndarray:\n",
    "    return np.where(np.isin(y, [-1]), 0, y)\n",
    "\n",
    "X_train: np.ndarray = addBiasColumn(X_train)\n",
    "X_test: np.ndarray  = addBiasColumn(X_test)\n",
    "w_opt: np.ndarray = np.matmul(np.matmul(inv(np.matmul(X_train.T, X_train)),X_train.T), y_train)\n",
    "\n",
    "network: AdalineClassifier = AdalineClassifier(alpha = 4)##1e-4\n",
    "network.fitAdaline(X_train, y_train)\n",
    "\n",
    "y_p: np.ndarray = network.predictAdaline(X_test)\n",
    "y_pdg: np.ndarray = [ (1 if np.dot(w_opt, X_test[i])> 0.5 else -1) for i in range(len(X_test))]\n",
    "\n",
    "y_p = convertNegativeToZeroExpresionMC(y_p)\n",
    "y_pdg = convertNegativeToZeroExpresionMC(y_pdg)\n",
    "\n",
    "mc_y: np.ndarray = confusion_matrix(y_test, y_p, labels=[1,0]).ravel()\n",
    "mc_y_pdg: np.ndarray = confusion_matrix(y_test, y_pdg, labels=[1,0]).ravel()\n",
    "print(\"| tn | fp | fn | tp |\")\n",
    "print(conlaFuncion)\n",
    "print(mc_y)\n",
    "print(mc_y_pdg)\n",
    "\n",
    "print(\"PESOS ADALINE = \", network.getWeigths())\n",
    "print(\"PESOS INI ADALINE= \", network.getWeigthsInit())\n",
    "plt.plot(network.getLoss())\n",
    "plt.show()\n",
    "#-------------------------------------------------\n",
    "# tn, fp, fn, tp <- [w, x, y, z]\n",
    "# matriz de confusion del perceptron multicapa [4037, 1428, 1567, 4968]\n",
    "# matriz de confusion del Adaline [5465    0 6523   12]\n",
    "# matriz de confusion obteniendo los pesos por multiplicacion de matrices [3892 1573 1427 5108]\n",
    "# pesos random usados por adaline\n",
    "# PESOS =  [20.99808024  0.5270072  -0.0791013   2.73576682  4.81105152  1.46994978\n",
    "#   3.41242629 -1.65356074  2.6820606  -1.92759262 -0.235847    0.0272522\n",
    "#   0.67340398  2.235122    0.25877167  4.06403353  0.90794609 -0.13899405]\n",
    "# PESOS INI =  [20.99808024  0.5270072  -0.0791013   2.73576682  4.81105152  1.46994978\n",
    "#   3.41242629 -1.65356074  2.6820606  -1.92759262 -0.235847    0.0272522\n",
    "#   0.67340398  2.235122    0.25877167  4.06403353  0.90794609 -0.13899405]\n",
    "#-------------------------------------------------- \n",
    "# matriz de confusion del perceptron multicapa [4201, 1276, 1521, 5002]\n",
    "# matriz de confusion del Adaline [5477    0 6523    0]\n",
    "# matriz de confusion obteniendo los pesos por multiplicacion de matrices [3955 1522 1424 5099]\n",
    "# pesos random usados por adaline\n",
    "# PESOS =  [ 2.66808024  0.28479677  0.01700008  0.28138062  0.01098598 -0.0159212\n",
    "#   0.18818795 -0.0179874   0.32250433  0.01098272 -0.23231329  0.36416046\n",
    "#   0.43217375 -0.01084406 -0.04439568  0.01214201 -0.04953691 -0.02525613]\n",
    "# PESOS INI =  [ 2.66808024  0.28479677  0.01700008  0.28138062  0.01098598 -0.0159212\n",
    "#   0.18818795 -0.0179874   0.32250433  0.01098272 -0.23231329  0.36416046\n",
    "#   0.43217375 -0.01084406 -0.04439568  0.01214201 -0.04953691 -0.02525613]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ayudandonos de una biblioteca de Pandas para poder visualizar los datos de importancia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PARA EL PERCEPTRON MULTICAPA\n",
      "\n",
      "                Predicción Negativa  Predicción Positiva  Accuracy    Recall  \\\n",
      "Clase Negativa                 4186                 1225  0.768917  0.765063   \n",
      "Clase Positiva                 1548                 5041  0.768917  0.765063   \n",
      "\n",
      "                Precision       TNR  \n",
      "Clase Negativa     0.8045  0.773609  \n",
      "Clase Positiva     0.8045  0.773609  \n",
      "\n",
      "PARA ADALINE\n",
      "\n",
      "                Predicción Negativa  Predicción Positiva  Accuracy  Recall  \\\n",
      "Clase Negativa                 5411                    0  0.450917     0.0   \n",
      "Clase Positiva                 6589                    0  0.450917     0.0   \n",
      "\n",
      "                Precision  TNR  \n",
      "Clase Negativa   0.000001  1.0  \n",
      "Clase Positiva   0.000001  1.0  \n",
      "\n",
      "UTILIZANDO UN PESO POR MULTIPLICACION DE MATRICES\n",
      "\n",
      "                Predicción Negativa  Predicción Positiva  Accuracy    Recall  \\\n",
      "Clase Negativa                 3953                 1458  0.759833  0.783882   \n",
      "Clase Positiva                 1424                 5165  0.759833  0.783882   \n",
      "\n",
      "                Precision       TNR  \n",
      "Clase Negativa   0.779858  0.730549  \n",
      "Clase Positiva   0.779858  0.730549  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_classification_table(TN: int, FP: int, FN: int, TP: int, row_names: List[str], column_names: List[str]) -> pd.DataFrame:\n",
    "    accuracy: float = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN != 0) else 0.000001\n",
    "    recall: float = TP / (TP + FN) if (TP+FN != 0) else 0.000001\n",
    "    precision: float = TP / (TP + FP) if (TP + FP != 0) else 0.000001\n",
    "    tnr: float = TN / (TN + FP) if (TN + FP != 0) else 0.000001\n",
    "    \n",
    "    data: List[List[float]] = [[TN, FP], [FN, TP]]\n",
    "    index: List[str] = row_names\n",
    "    columns: List[str] = column_names\n",
    "    \n",
    "    df: pd.DataFrame = pd.DataFrame(data, index=index, columns=columns)\n",
    "    df['Accuracy'] = accuracy\n",
    "    df['Recall'] = recall\n",
    "    df['Precision'] = precision\n",
    "    df['TNR'] = tnr\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "row_names: List[str] = ['Clase Negativa', 'Clase Positiva']\n",
    "column_names: List[str] = ['Predicción Negativa', 'Predicción Positiva']\n",
    "\n",
    "print(\"\\nPARA EL PERCEPTRON MULTICAPA\\n\")\n",
    "print(create_classification_table(conlaFuncion[0], conlaFuncion[1], conlaFuncion[2], conlaFuncion[3], row_names, column_names))  \n",
    "print(\"\\nPARA ADALINE\\n\")\n",
    "print(create_classification_table(mc_y[0], mc_y[1], mc_y[2], mc_y[3], row_names, column_names))\n",
    "print(\"\\nUTILIZANDO UN PESO POR MULTIPLICACION DE MATRICES\\n\")\n",
    "print(create_classification_table(mc_y_pdg[0], mc_y_pdg[1], mc_y_pdg[2], mc_y_pdg[3], row_names, column_names))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este problema de clasificación nos interesaría cuantas menor predicciones negativas falsas mejor, ya que esto significaría que a un paciente no se le ha diagnosticada nada cuando en realidad padece de la enfermedad. Por lo tanto sería bueno fijarse en el Recall, que mide la proporción de casos positivos que son correctamente identificados por el modelo, es decir, la capacidad del modelo para encontrar todos los casos positivos. Como resulta que el recal es tp/(tp+fn) si tenemos que el recall es muy grande significaría que hay muy pocos falsos negativos y si resulta lo contrario es que hay muchos falsos negativos, es decir, que funciona pero no tan bien para este problema. Por lo tanto el modelo que más recall tiene es el modelo 3 en el que obteniamos lo pesos con el método normal de Gauss."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
